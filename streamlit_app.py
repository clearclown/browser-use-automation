#!/usr/bin/env python3
"""
Automated Research Assistant - Streamlit Web UI
å®Œå…¨è‡ªå‹•åŒ–ç ”ç©¶æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  - Streamlit Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

è¤‡æ•°è¡Œå…¥åŠ›ã€ãƒãƒ«ãƒLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ“ä½œãŒå¯èƒ½ãªGUI
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path

import streamlit as st

from automated_research.llm_provider import get_available_providers, get_llm
from automated_research.main import AutomatedResearchAssistant


def init_session_state():
	"""ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
	if 'research_running' not in st.session_state:
		st.session_state.research_running = False
	if 'results' not in st.session_state:
		st.session_state.results = None
	if 'logs' not in st.session_state:
		st.session_state.logs = []


def add_log(message: str):
	"""ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
	timestamp = datetime.now().strftime('%H:%M:%S')
	st.session_state.logs.append(f'[{timestamp}] {message}')


async def run_research(
	provider: str,
	model: str | None,
	research_topic: str,
	research_question: str,
	keywords: list[str],
	specific_interests: list[str],
	research_background: str,
	year_start: int,
	year_end: int,
	max_papers: int,
	headless: bool,
):
	"""ç ”ç©¶èª¿æŸ»ã‚’å®Ÿè¡Œ"""
	try:
		# ãƒ–ãƒ©ã‚¦ã‚¶ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·ï¼ˆç’°å¢ƒå¤‰æ•°ã§è¨­å®š - æœ€åˆã«å®Ÿè¡Œï¼‰
		import os

		os.environ['TIMEOUT_NavigateToUrlEvent'] = '60'  # 60ç§’
		os.environ['TIMEOUT_BrowserStateRequestEvent'] = '120'  # 120ç§’
		os.environ['TIMEOUT_ClickElementEvent'] = '30'  # 30ç§’

		add_log(f'ğŸš€ ç ”ç©¶èª¿æŸ»ã‚’é–‹å§‹: {research_topic}')
		add_log(f'ğŸ“Š LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider}')

		# LLMåˆæœŸåŒ–
		llm = get_llm(provider=provider, model=model, temperature=0.4)
		add_log(f'âœ… {provider.upper()} ã‚’åˆæœŸåŒ–å®Œäº†')

		# ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
		assistant = AutomatedResearchAssistant(
			llm=llm, headless=headless, max_papers=max_papers, non_interactive=True, research_topic=research_topic
		)

		# ç ”ç©¶æƒ…å ±ã‚’æ‰‹å‹•è¨­å®šï¼ˆå¯¾è©±å‹ã‚¹ã‚­ãƒƒãƒ—ï¼‰
		research_info = {
			'research_topic': research_topic,
			'research_question': research_question,
			'keywords': keywords,
			'specific_interests': specific_interests,
			'research_background': research_background,
			'year_range': {'start': year_start, 'end': year_end},
			'databases': ['ieee'],
		}

		# ã‚¹ãƒ†ãƒƒãƒ—1: ç ”ç©¶æƒ…å ±ä¿å­˜
		add_log('ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ç ”ç©¶æƒ…å ±ã‚’ä¿å­˜')
		output_path = assistant.data_dir / f'research_info_{assistant.session_id}.json'
		with open(output_path, 'w', encoding='utf-8') as f:
			json.dump(research_info, f, indent=2, ensure_ascii=False)
		add_log(f'ğŸ’¾ {output_path}')

		# ã‚¹ãƒ†ãƒƒãƒ—2: PRISMAæ¤œç´¢æˆ¦ç•¥ç”Ÿæˆ
		add_log('ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2: PRISMAæ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆä¸­...')
		search_strategy = await assistant._step2_generate_strategy(research_info)
		add_log(f'âœ… {len(search_strategy.get("search_queries", []))}å€‹ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ')

		# ã‚¹ãƒ†ãƒƒãƒ—3: è«–æ–‡æ¤œç´¢
		add_log('ğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: IEEE Xploreã§è«–æ–‡ã‚’æ¤œç´¢ä¸­...')
		papers = await assistant._step3_search_papers(search_strategy)
		add_log(f'âœ… {len(papers)}ä»¶ã®è«–æ–‡ã‚’åé›†')

		if not papers:
			add_log('âš ï¸ è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
			return {
				'success': False,
				'message': 'è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚',
				'papers': [],
			}

		# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
		add_log(f'ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—4: {len(papers)}ä»¶ã®è«–æ–‡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...')
		reports = await assistant._step4_generate_reports(papers, research_info)
		add_log(f'âœ… {len(reports)}ä»¶ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆå®Œäº†')

		# ã‚¹ãƒ†ãƒƒãƒ—5: çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
		add_log('ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—5: çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...')
		await assistant._step5_generate_summary(reports, research_info, search_strategy)
		add_log('âœ… çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†')

		# çµæœã‚’è¿”ã™
		summary_path = assistant.reports_dir / f'summary_report_{assistant.session_id}.md'
		with open(summary_path, encoding='utf-8') as f:
			summary_content = f.read()

		add_log('ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼')

		return {
			'success': True,
			'message': 'ç ”ç©¶èª¿æŸ»ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ',
			'papers': papers,
			'reports': reports,
			'summary_report': summary_content,
			'summary_path': str(summary_path),
			'session_id': assistant.session_id,
		}

	except Exception as e:
		add_log(f'âŒ ã‚¨ãƒ©ãƒ¼: {e}')
		return {'success': False, 'message': f'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}', 'papers': []}


def main():
	"""Streamlit ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
	st.set_page_config(page_title='è‡ªå‹•ç ”ç©¶æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ', page_icon='ğŸ¤–', layout='wide', initial_sidebar_state='expanded')

	init_session_state()

	# ãƒ˜ãƒƒãƒ€ãƒ¼
	st.title('ğŸ¤– å®Œå…¨è‡ªå‹•åŒ–ç ”ç©¶æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ')
	st.markdown('---')
	st.markdown(
		"""
	**PRISMA 2020æº–æ‹ ã®è‡ªå‹•æ–‡çŒ®èª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ **

	ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã‚’è‡ªå‹•å®Ÿè¡Œã—ã¾ã™ï¼š
	1. ç ”ç©¶å†…å®¹ã®ãƒ’ã‚¢ãƒªãƒ³ã‚°
	2. PRISMAæ–¹å¼ã®æ¤œç´¢æˆ¦ç•¥ç«‹æ¡ˆ
	3. IEEE Xploreã§ã®è‡ªå‹•æ¤œç´¢
	4. è«–æ–‡ã®è©³ç´°åˆ†æï¼ˆè½åˆé™½ä¸€å¼ï¼‰
	5. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
	"""
	)

	# ã‚µã‚¤ãƒ‰ãƒãƒ¼: LLMè¨­å®š
	with st.sidebar:
		st.header('âš™ï¸ LLMè¨­å®š')

		# åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—
		available_providers = get_available_providers()

		if not available_providers:
			st.error('âŒ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
			st.stop()

		provider = st.selectbox(
			'LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼',
			options=available_providers,
			help='ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠï¼ˆ.envã§è¨­å®šã•ã‚ŒãŸAPIã‚­ãƒ¼ãŒå¿…è¦ï¼‰',
		)

		# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
		default_models = {
			'openai': 'gpt-4o',
			'claude': 'claude-3-5-sonnet-20241022',
			'deepseek': 'deepseek-chat',
			'google': 'gemini-2.0-flash-exp',
			'groq': 'llama-3.3-70b-versatile',
		}

		model = st.text_input('ãƒ¢ãƒ‡ãƒ«åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰', value=default_models.get(provider, ''), help='ç©ºæ¬„ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨')

		st.markdown('---')
		st.header('ğŸ“Š æ¤œç´¢è¨­å®š')

		max_papers = st.slider('æœ€å¤§è«–æ–‡æ•°', min_value=1, max_value=1000, value=10, step=1)
		headless = st.checkbox('ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰', value=True, help='ãƒ–ãƒ©ã‚¦ã‚¶ã‚’éè¡¨ç¤ºã§å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰')

		year_start = st.number_input('é–‹å§‹å¹´', min_value=2000, max_value=2025, value=2022, step=1)
		year_end = st.number_input('çµ‚äº†å¹´', min_value=2000, max_value=2025, value=2025, step=1)

	# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: ç ”ç©¶æƒ…å ±å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
	st.header('ğŸ“ ç ”ç©¶æƒ…å ±å…¥åŠ›')

	col1, col2 = st.columns([2, 1])

	with col1:
		research_topic = st.text_input(
			'ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ *',
			placeholder='ä¾‹: Large Language Models (LLM) ã®æœ€æ–°ç ”ç©¶å‹•å‘',
			help='èª¿æŸ»ã—ãŸã„ç ”ç©¶ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„',
		)

		research_question = st.text_area(
			'ç ”ç©¶èª²é¡Œãƒ»ãƒªã‚µãƒ¼ãƒã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ *',
			placeholder='ä¾‹: LLMã®æ€§èƒ½å‘ä¸Šã€åŠ¹ç‡åŒ–ã€å¿œç”¨åˆ†é‡ã®æœ€æ–°æŠ€è¡“ã¯ä½•ã‹ï¼Ÿ',
			height=100,
			help='è¤‡æ•°è¡Œã§è©³ç´°ã«è¨˜è¿°ã§ãã¾ã™',
		)

		research_background = st.text_area(
			'ç ”ç©¶èƒŒæ™¯',
			placeholder='ä¾‹: LLMã¯è‡ªç„¶è¨€èªå‡¦ç†ã®ä¸­æ ¸æŠ€è¡“ã¨ãªã£ã¦ãŠã‚Šã€æœ¬èª¿æŸ»ã§ã¯æœ€æ–°ç ”ç©¶å‹•å‘ã‚’ä½“ç³»çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã€‚',
			height=150,
			help='ç ”ç©¶ã®èƒŒæ™¯ã‚„ç›®çš„ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°è¡Œå¯ï¼‰',
		)

	with col2:
		keywords_input = st.text_area(
			'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ1è¡Œã«1ã¤ï¼‰ *',
			placeholder='Large Language Model\nLLM\ntransformer\nGPT\nBERT',
			height=200,
			help='æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’1è¡Œã«1ã¤ãšã¤å…¥åŠ›',
		)

		interests_input = st.text_area(
			'ç‰¹å®šã®é–¢å¿ƒé ˜åŸŸï¼ˆ1è¡Œã«1ã¤ï¼‰',
			placeholder='ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ”¹å–„\nè¨ˆç®—åŠ¹ç‡ã®å‘ä¸Š\nFew-shot learning',
			height=200,
			help='ç‰¹ã«æ³¨ç›®ã—ãŸã„é ˜åŸŸã‚’1è¡Œã«1ã¤ãšã¤å…¥åŠ›',
		)

	# å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
	keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]
	specific_interests = [i.strip() for i in interests_input.split('\n') if i.strip()]

	# å®Ÿè¡Œãƒœã‚¿ãƒ³
	st.markdown('---')

	col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 3])

	with col_btn1:
		run_button = st.button('ğŸš€ ç ”ç©¶èª¿æŸ»ã‚’é–‹å§‹', type='primary', disabled=st.session_state.research_running, use_container_width=True)

	with col_btn2:
		if st.button('ğŸ—‘ï¸ ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢', use_container_width=True):
			st.session_state.logs = []
			st.rerun()

	# å…¥åŠ›ãƒã‚§ãƒƒã‚¯
	if run_button:
		if not research_topic or not research_question or not keywords:
			st.error('âŒ å¿…é ˆé …ç›®ï¼ˆ*ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„')
		else:
			st.session_state.research_running = True
			st.session_state.results = None

			# éåŒæœŸå®Ÿè¡Œ
			with st.spinner('ğŸ”„ ç ”ç©¶èª¿æŸ»ã‚’å®Ÿè¡Œä¸­...'):
				results = asyncio.run(
					run_research(
						provider=provider,
						model=model if model else None,
						research_topic=research_topic,
						research_question=research_question,
						keywords=keywords,
						specific_interests=specific_interests,
						research_background=research_background,
						year_start=year_start,
						year_end=year_end,
						max_papers=max_papers,
						headless=headless,
					)
				)

				st.session_state.results = results
				st.session_state.research_running = False
				st.rerun()

	# ãƒ­ã‚°è¡¨ç¤º
	if st.session_state.logs:
		st.markdown('---')
		st.header('ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°')
		log_container = st.container(height=300)
		with log_container:
			for log in st.session_state.logs:
				st.text(log)

	# çµæœè¡¨ç¤º
	if st.session_state.results:
		st.markdown('---')
		st.header('ğŸ“Š çµæœ')

		results = st.session_state.results

		if results['success']:
			st.success(f'âœ… {results["message"]}')

			# ã‚¿ãƒ–ã§çµæœã‚’è¡¨ç¤º
			tab1, tab2, tab3 = st.tabs(['ğŸ“š åé›†è«–æ–‡', 'ğŸ“„ çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ', 'ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«'])

			with tab1:
				st.subheader(f'åé›†è«–æ–‡ä¸€è¦§ï¼ˆ{len(results["papers"])}ä»¶ï¼‰')

				for idx, paper in enumerate(results['papers'], 1):
					with st.expander(f'{idx}. {paper.get("title", "Unknown")}'):
						st.markdown(f'**è‘—è€…:** {", ".join(paper.get("authors", ["Unknown"]))}')
						st.markdown(f'**ç™ºè¡Œæ—¥:** {paper.get("published_date", "N/A")}')
						st.markdown(f'**URL:** [{paper.get("url", "N/A")}]({paper.get("url", "#")})')

						if 'abstract' in paper:
							st.markdown('**æ¦‚è¦:**')
							st.markdown(paper['abstract'])

			with tab2:
				st.subheader('çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ')
				st.markdown(results.get('summary_report', ''))

				# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
				if 'summary_report' in results:
					st.download_button(
						label='ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆMarkdownï¼‰',
						data=results['summary_report'],
						file_name=f'research_report_{results["session_id"]}.md',
						mime='text/markdown',
					)

			with tab3:
				st.subheader('ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«')
				st.markdown(f'**ã‚»ãƒƒã‚·ãƒ§ãƒ³ID:** `{results["session_id"]}`')
				st.markdown(f'**çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ:** `{results.get("summary_path", "N/A")}`')
				st.markdown('**å€‹åˆ¥ãƒ¬ãƒãƒ¼ãƒˆ:** `automated_research/reports/session_{}/`'.format(results['session_id']))
				st.markdown('**ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:** `automated_research/data/`')

		else:
			st.error(f'âŒ {results["message"]}')


if __name__ == '__main__':
	main()
