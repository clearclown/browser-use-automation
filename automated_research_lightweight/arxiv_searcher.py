"""
arXiv API Searcher

å…¬å¼APIã‚’ä½¿ç”¨ã—ãŸè»½é‡å®Ÿè£…ï¼ˆèªè¨¼ä¸è¦ï¼‰
ãƒªã‚½ãƒ¼ã‚¹: 5-10MB, <1% CPU
"""

import asyncio
from typing import Any

try:
	import arxiv
except ImportError:
	print('âŒ arxiv ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: uv pip install arxiv')
	arxiv = None


class ArxivSearcher:
	"""arXivå…¬å¼APIæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³"""

	def __init__(self, max_results: int = 10):
		"""
		Args:
			max_results: æœ€å¤§å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
		"""
		if arxiv is None:
			raise ImportError('arxiv ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™: uv pip install arxiv')

		self.max_results = max_results

	async def search_papers(
		self,
		query: str,
		year_start: int | None = None,
		year_end: int | None = None,
		max_results: int | None = None,
	) -> list[dict[str, Any]]:
		"""
		arXiv APIã§è«–æ–‡ã‚’æ¤œç´¢

		Args:
			query: æ¤œç´¢ã‚¯ã‚¨ãƒª
			year_start: é–‹å§‹å¹´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
			year_end: çµ‚äº†å¹´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
			max_results: æœ€å¤§å–å¾—ä»¶æ•°ï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰

		Returns:
			è«–æ–‡æƒ…å ±ã®ãƒªã‚¹ãƒˆ
		"""
		papers = []
		max_count = max_results if max_results is not None else self.max_results

		# arxiv.Search APIã¯åŒæœŸãªã®ã§ã€asyncio.to_threadã§éåŒæœŸåŒ–
		search = arxiv.Search(query=query, max_results=max_count, sort_by=arxiv.SortCriterion.SubmittedDate)

		try:
			# éåŒæœŸå®Ÿè¡Œ
			results = await asyncio.to_thread(lambda: list(search.results()))

			for paper in results:
				# å¹´ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
				if year_start or year_end:
					paper_year = paper.published.year
					if year_start and paper_year < year_start:
						continue
					if year_end and paper_year > year_end:
						continue

				papers.append(
					{
						'title': paper.title,
						'authors': [author.name for author in paper.authors],
						'published_date': paper.published.strftime('%Y-%m-%d'),
						'url': paper.entry_id,
						'pdf_url': paper.pdf_url,
						'abstract': paper.summary,
						'source': 'arXiv API',
						'categories': paper.categories,
					}
				)

		except Exception as e:
			print(f'âŒ arXiv API ã‚¨ãƒ©ãƒ¼: {e}')

		return papers


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
async def _test():
	"""å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ"""
	searcher = ArxivSearcher()

	print('ğŸ” arXiv APIæ¤œç´¢ãƒ†ã‚¹ãƒˆ')
	print('æ¤œç´¢ã‚¯ã‚¨ãƒª: "deep learning"')
	print('')

	papers = await searcher.search_papers(query='deep learning', year_start=2023, year_end=2025, max_results=3)

	print(f'âœ… {len(papers)}ä»¶ã®è«–æ–‡ã‚’å–å¾—\n')

	for idx, paper in enumerate(papers, 1):
		print(f'{idx}. {paper["title"]}')
		print(f'   è‘—è€…: {", ".join(paper["authors"][:3])}')
		print(f'   ç™ºè¡Œæ—¥: {paper["published_date"]}')
		print(f'   URL: {paper["url"]}')
		print(f'   PDF: {paper["pdf_url"]}')
		print('')


if __name__ == '__main__':
	asyncio.run(_test())
