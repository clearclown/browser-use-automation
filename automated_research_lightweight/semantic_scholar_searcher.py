"""
Semantic Scholar API Searcher

å…¬å¼APIã‚’ä½¿ç”¨ã—ãŸè»½é‡å®Ÿè£…ï¼ˆèªè¨¼ä¸è¦ï¼‰
ãƒªã‚½ãƒ¼ã‚¹: 5-10MB, <1% CPU

API Docs: https://api.semanticscholar.org/api-docs/
"""

import asyncio
from typing import Any

import httpx


class SemanticScholarSearcher:
	"""Semantic Scholarå…¬å¼APIæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³"""

	def __init__(self, timeout: int = 30):
		"""
		Args:
			timeout: HTTPæ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰
		"""
		self.timeout = timeout
		self.base_url = 'https://api.semanticscholar.org/graph/v1'

		# APIãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆAPI Keyã¯ä¸è¦ã ãŒã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«æ³¨æ„ï¼‰
		self.headers = {
			'Accept': 'application/json',
		}

	async def search_papers(
		self,
		query: str,
		year_start: int | None = None,
		year_end: int | None = None,
		max_results: int = 10,
	) -> list[dict[str, Any]]:
		"""
		Semantic Scholar APIã§è«–æ–‡ã‚’æ¤œç´¢

		Args:
			query: æ¤œç´¢ã‚¯ã‚¨ãƒª
			year_start: é–‹å§‹å¹´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
			year_end: çµ‚äº†å¹´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
			max_results: æœ€å¤§å–å¾—ä»¶æ•°

		Returns:
			è«–æ–‡æƒ…å ±ã®ãƒªã‚¹ãƒˆ
		"""
		papers = []

		async with httpx.AsyncClient(headers=self.headers, timeout=self.timeout) as client:
			# æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
			params = {
				'query': query,
				'limit': max_results,
				'fields': 'paperId,title,authors,year,abstract,url,openAccessPdf,citationCount,influentialCitationCount',
			}

			# å¹´ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆSemantic Scholarã¯yearãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯èƒ½ï¼‰
			if year_start and year_end:
				params['year'] = f'{year_start}-{year_end}'
			elif year_start:
				params['year'] = f'{year_start}-'
			elif year_end:
				params['year'] = f'-{year_end}'

			try:
				# APIå‘¼ã³å‡ºã—
				response = await client.get(f'{self.base_url}/paper/search', params=params)
				response.raise_for_status()

				data = response.json()

				# è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹
				for paper_data in data.get('data', []):
					paper = self._parse_paper(paper_data)
					if paper:
						papers.append(paper)

			except httpx.HTTPStatusError as e:
				print(f'âŒ Semantic Scholar HTTPã‚¨ãƒ©ãƒ¼: {e.response.status_code}')
			except httpx.RequestError as e:
				print(f'âŒ Semantic Scholar ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}')
			except Exception as e:
				print(f'âŒ Semantic Scholar äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}')

		return papers

	def _parse_paper(self, paper_data: dict[str, Any]) -> dict[str, Any] | None:
		"""
		è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹

		Args:
			paper_data: APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿

		Returns:
			è«–æ–‡æƒ…å ±è¾æ›¸
		"""
		try:
			# è‘—è€…ãƒªã‚¹ãƒˆ
			authors = [author.get('name', 'Unknown') for author in paper_data.get('authors', [])]

			# PDF URLï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ã‚¢ã‚¯ã‚»ã‚¹ã®å ´åˆï¼‰
			pdf_url = None
			if paper_data.get('openAccessPdf'):
				pdf_url = paper_data['openAccessPdf'].get('url')

			# Semantic Scholar URL
			paper_id = paper_data.get('paperId', '')
			semantic_url = f'https://www.semanticscholar.org/paper/{paper_id}' if paper_id else None

			return {
				'title': paper_data.get('title', 'Unknown Title'),
				'authors': authors,
				'published_date': str(paper_data.get('year', 'N/A')),
				'url': semantic_url or paper_data.get('url', 'N/A'),
				'pdf_url': pdf_url,
				'abstract': paper_data.get('abstract', 'ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆãªã—'),
				'source': 'Semantic Scholar API',
				'citation_count': paper_data.get('citationCount', 0),
				'influential_citation_count': paper_data.get('influentialCitationCount', 0),
			}

		except Exception as e:
			print(f'âš ï¸ è«–æ–‡ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}')
			return None


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
async def _test():
	"""å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ"""
	searcher = SemanticScholarSearcher()

	print('ğŸ” Semantic Scholar APIæ¤œç´¢ãƒ†ã‚¹ãƒˆ')
	print('æ¤œç´¢ã‚¯ã‚¨ãƒª: "deep learning"')
	print('')

	papers = await searcher.search_papers(query='deep learning', year_start=2023, year_end=2025, max_results=3)

	print(f'âœ… {len(papers)}ä»¶ã®è«–æ–‡ã‚’å–å¾—\n')

	for idx, paper in enumerate(papers, 1):
		print(f'{idx}. {paper["title"]}')
		print(f'   è‘—è€…: {", ".join(paper["authors"][:3])}')
		print(f'   ç™ºè¡Œæ—¥: {paper["published_date"]}')
		print(f'   URL: {paper["url"]}')
		print(f'   å¼•ç”¨æ•°: {paper["citation_count"]} (å½±éŸ¿åŠ›: {paper["influential_citation_count"]})')
		if paper.get('pdf_url'):
			print(f'   PDF: {paper["pdf_url"]}')
		print('')


if __name__ == '__main__':
	asyncio.run(_test())
