"""
Ochiai-style paper analysis and report generation
è½åˆé™½ä¸€å¼è«–æ–‡åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Any

from dotenv import load_dotenv

from automated_research.prompts.system_prompts import (
	FINAL_SUMMARY_PROMPT,
	OCHIAI_STYLE_ANALYSIS_PROMPT,
)
from langchain_core.messages import HumanMessage
from automated_research.llm_provider import get_llm

load_dotenv()

logger = logging.getLogger(__name__)


class OchiaiReportGenerator:
	"""è½åˆé™½ä¸€å¼ã®è«–æ–‡åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

	def __init__(self, llm: Any | None = None):
		self.llm = llm or get_llm(temperature=0.4)

	async def generate_paper_report(
		self, paper_info: dict[str, Any], research_context: dict[str, Any], pdf_content: str | None = None
	) -> str:
		"""
		å˜ä¸€ã®è«–æ–‡ã«å¯¾ã—ã¦è½åˆé™½ä¸€å¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

		Args:
			paper_info: è«–æ–‡ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
			research_context: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
			pdf_content: PDFæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

		Returns:
			ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆ
		"""
		logger.info(f'ğŸ“ Generating Ochiai-style report for: {paper_info.get("title", "Unknown")}')

		# è«–æ–‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
		metadata_text = self._format_paper_metadata(paper_info)

		# PDFå†…å®¹ï¼ˆãªã‘ã‚Œã°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
		content_text = pdf_content if pdf_content else '(PDF content not available - using metadata only)'

		# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢
		user_research_text = self._format_research_context(research_context)

		# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
		prompt = OCHIAI_STYLE_ANALYSIS_PROMPT.format(
			paper_metadata=metadata_text, paper_content=content_text, user_research=user_research_text
		)

		messages = [HumanMessage(content=prompt)]

		try:
			# LLMã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
			response = await self.llm.ainvoke(messages)
			report = response.content

			# ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
			if '```markdown' in report:
				report = report.split('```markdown')[1].split('```')[0].strip()
			elif '```' in report:
				# æœ€åˆã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
				parts = report.split('```')
				if len(parts) >= 3:
					report = parts[1].strip()

			return report

		except Exception as e:
			logger.error(f'Error generating report: {e}')
			return self._generate_fallback_report(paper_info)

	def _format_paper_metadata(self, paper_info: dict[str, Any]) -> str:
		"""è«–æ–‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«æ•´å½¢"""
		parts = []

		parts.append(f'Title: {paper_info.get("title", "N/A")}')
		parts.append(f'Authors: {", ".join(paper_info.get("authors", ["N/A"]))}')
		parts.append(f'Year: {paper_info.get("year", "N/A")}')
		parts.append(f'Publication: {paper_info.get("publication", "N/A")}')
		parts.append(f'DOI: {paper_info.get("doi", "N/A")}')
		parts.append(f'URL: {paper_info.get("url", "N/A")}')

		if paper_info.get('abstract'):
			parts.append(f'\nAbstract:\n{paper_info["abstract"]}')

		return '\n'.join(parts)

	def _format_research_context(self, research_context: dict[str, Any]) -> str:
		"""ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«æ•´å½¢"""
		parts = []

		parts.append(f'ç ”ç©¶ãƒ†ãƒ¼ãƒ: {research_context.get("research_theme", "N/A")}')
		parts.append(f'ç ”ç©¶åˆ†é‡: {research_context.get("research_field", "N/A")}')

		if research_context.get('research_purpose'):
			parts.append(f'ç ”ç©¶ç›®çš„: {research_context["research_purpose"]}')

		if research_context.get('problem_statement'):
			parts.append(f'å•é¡Œæ„è­˜: {research_context["problem_statement"]}')

		if research_context.get('specific_technologies'):
			tech_list = ', '.join(research_context['specific_technologies'])
			parts.append(f'æ³¨ç›®æŠ€è¡“: {tech_list}')

		return '\n'.join(parts)

	def _generate_fallback_report(self, paper_info: dict[str, Any]) -> str:
		"""ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
		logger.warning('Falling back to basic report generation')

		title = paper_info.get('title', 'Unknown Title')
		authors = ', '.join(paper_info.get('authors', ['Unknown']))
		year = paper_info.get('year', 'Unknown')
		url = paper_info.get('url', '#')

		report = f"""## title: "{title}"
date: {datetime.now().strftime('%Y-%m-%d')}
categories: Research

### 1. ã©ã‚“ãªã‚‚ã®ï¼Ÿ
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### 2. å…ˆè¡Œç ”ç©¶ã¨æ¯”ã¹ã¦ã©ã“ãŒã™ã”ã„ã®ï¼Ÿ
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### 3. æŠ€è¡“ã‚„æ‰‹æ³•ã®"ã‚­ãƒ¢"ã¯ã©ã“ã«ã‚ã‚‹ï¼Ÿ
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### 4. ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸï¼Ÿ
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### 5. è­°è«–ã¯ã‚ã‚‹ã‹ï¼Ÿ
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### 6. æ¬¡ã«èª­ã‚€ã¹ãè«–æ–‡ã¯ã‚ã‚‹ã‹ï¼Ÿ
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### 7. è‡ªåˆ†ã®ç ”ç©¶ã¨ã®é–¢é€£
ï¼ˆè©³ç´°ãªåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼‰

### è«–æ–‡æƒ…å ±ãƒ»ãƒªãƒ³ã‚¯
- [{authors}, "{title}," {year}]({url})
"""
		return report

	async def generate_summary_report(
		self, all_reports: list[str], research_context: dict[str, Any], search_strategy: dict[str, Any]
	) -> str:
		"""
		ã™ã¹ã¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’çµ±åˆã—ã¦ç·åˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ

		Args:
			all_reports: å€‹åˆ¥ã®è«–æ–‡ãƒ¬ãƒãƒ¼ãƒˆãƒªã‚¹ãƒˆ
			research_context: ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
			search_strategy: æ¤œç´¢æˆ¦ç•¥

		Returns:
			çµ±åˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ï¼‰
		"""
		logger.info('ğŸ“Š Generating comprehensive summary report...')

		# ç ”ç©¶ãƒ†ãƒ¼ãƒã‚’å–å¾—
		research_theme = research_context.get('research_theme', 'Unknown Theme')

		# æ¤œç´¢æˆ¦ç•¥ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«
		strategy_text = self._format_search_strategy(search_strategy)

		# ã™ã¹ã¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’çµåˆ
		reports_text = '\n\n---\n\n'.join(all_reports)

		# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
		prompt = FINAL_SUMMARY_PROMPT.format(
			user_research=self._format_research_context(research_context),
			research_theme=research_theme,
			search_strategy=strategy_text,
			all_reports=reports_text,
			generation_date=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
			total_papers=len(all_reports),
		)

		messages = [HumanMessage(content=prompt)]

		try:
			response = await self.llm.ainvoke(messages)
			summary = response.content

			# ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
			if '```markdown' in summary:
				summary = summary.split('```markdown')[1].split('```')[0].strip()
			elif '```' in summary:
				parts = summary.split('```')
				if len(parts) >= 3:
					summary = parts[1].strip()

			return summary

		except Exception as e:
			logger.error(f'Error generating summary report: {e}')
			return self._generate_fallback_summary(research_theme, len(all_reports))

	def _format_search_strategy(self, strategy: dict[str, Any]) -> str:
		"""æ¤œç´¢æˆ¦ç•¥ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«æ•´å½¢"""
		parts = []

		if strategy.get('primary_keywords'):
			parts.append(f'ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {", ".join(strategy["primary_keywords"])}')

		if strategy.get('search_queries'):
			parts.append('\næ¤œç´¢ã‚¯ã‚¨ãƒª:')
			for i, query in enumerate(strategy['search_queries'], 1):
				parts.append(f'  {i}. {query}')

		return '\n'.join(parts)

	def _generate_fallback_summary(self, research_theme: str, paper_count: int) -> str:
		"""ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬çš„ãªçµ±åˆãƒ¬ãƒãƒ¼ãƒˆ"""
		return f"""# ä½“ç³»çš„æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼: {research_theme}

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
åˆè¨ˆ {paper_count} ä»¶ã®è«–æ–‡ã‚’åé›†ãƒ»åˆ†æã—ã¾ã—ãŸã€‚

ï¼ˆè©³ç´°ãªçµ±åˆåˆ†æãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å„è«–æ–‡ã®å€‹åˆ¥ãƒ¬ãƒãƒ¼ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ï¼‰

---
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ç·è«–æ–‡æ•°: {paper_count}
"""

	def save_report(self, report: str, output_path: Path, paper_title: str | None = None) -> None:
		"""ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
		output_path.parent.mkdir(parents=True, exist_ok=True)

		# ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ï¼‰
		if paper_title:
			# ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦å®‰å…¨ãªå½¢å¼ã«å¤‰æ›
			safe_title = ''.join(c if c.isalnum() or c in ' -_' else '_' for c in paper_title)
			safe_title = safe_title[:50]  # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
			filename = f'{safe_title}.md'
			final_path = output_path / filename
		else:
			final_path = output_path

		with open(final_path, 'w', encoding='utf-8') as f:
			f.write(report)

		logger.info(f'Report saved to: {final_path}')


async def main():
	"""ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
	# ãƒ†ã‚¹ãƒˆç”¨ã®è«–æ–‡æƒ…å ±
	paper_info = {
		'title': 'Test Paper on Machine Learning',
		'authors': ['John Doe', 'Jane Smith'],
		'year': 2023,
		'publication': 'IEEE Transactions on AI',
		'doi': '10.1109/TEST.2023',
		'url': 'https://ieeexplore.ieee.org/document/test',
		'abstract': 'This is a test abstract for machine learning research.',
	}

	research_context = {
		'research_theme': 'Machine Learning for Healthcare',
		'research_field': 'AI',
		'research_purpose': 'To improve diagnosis accuracy',
	}

	generator = OchiaiReportGenerator()

	# å€‹åˆ¥ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
	report = await generator.generate_paper_report(paper_info, research_context)

	# ä¿å­˜
	output_path = Path('automated_research/reports')
	generator.save_report(report, output_path, paper_info['title'])

	print('\nâœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ')
	print(f'\nãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ï¼ˆæŠœç²‹ï¼‰:\n{report[:500]}...')


if __name__ == '__main__':
	logging.basicConfig(level=logging.INFO)
	asyncio.run(main())
